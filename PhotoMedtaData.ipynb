{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elephant-xyz/notebook/blob/main/PhotoMedtaData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILCxMc0LIsi-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ˜ Welcome to Step 4 of Elephant Mining\n",
        "\n",
        "Congratulations on reaching **Step 4**! By now, youâ€™ve successfully **minted your County Data Group**. In this notebook, you'll use your **seed data** and **property images** to mint your **Photo** and **Photo Data Group**.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mz5mj3mc9A9r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Lh8z_QIuBx"
      },
      "source": [
        "## ðŸ“¥ Step 1: Upload the `.env` File\n",
        "\n",
        "This notebook requires a `.env` file containing your API keys and credentials. Create a file with the following environment variables:\n",
        "\n",
        "| Variable Name | Purpose |\n",
        "|---|---|\n",
        "| `OPENAI_API_KEY` | Access to OpenAI API |\n",
        "| `AWS_ACCESS_KEY_ID` | AWS access key |\n",
        "| `AWS_SECRET_ACCESS_KEY` | AWS secret access key |\n",
        "| `AWS_DEFAULT_REGION` | AWS REGION |\n",
        "| `S3_BUCKET_NAME` | Your S3 bucket name |\n",
        "| `IMAGE_FOLDER_NAME` | Image directory |\n",
        "| `IMAGES_DIR` | Directory path for images |\n",
        "| `ELEPHANT_PRIVATE_KEY` | Elephant wallet private key |\n",
        "| `PINATA_JWT` | Pinata authentication token |\n",
        "\n",
        "### To upload:\n",
        "1. Click the **folder icon** ðŸ“‚ in the left sidebar\n",
        "2. Click the **\"Upload\"** button\n",
        "3. Select your `.env` file\n",
        "\n",
        "### Example `.env` file:\n",
        "```env\n",
        "OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
        "AWS_ACCESS_KEY_ID=XXXXXX\n",
        "AWS_SECRET_ACCESS_KEY=XXXXXX\n",
        "S3_BUCKET_NAME=your-s3-bucket-name-here\n",
        "IMAGES_DIR=images\n",
        "IMAGE_FOLDER_NAME=images\n",
        "ELEPHANT_PRIVATE_KEY=xxxxx\n",
        "PINATA_JWT=xxxxx\n",
        "```\n",
        "\n",
        "> âš ï¸ **Security Note:** Never commit your `.env` file to version control or share it publicly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A8fm24ILQ8s"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q36E40RNVE3"
      },
      "source": [
        "## Step 2: Upload `upload_results.csv`\n",
        "\n",
        "Upload the `upload_results.csv` file to the `/content/` directory.\n",
        "\n",
        "> ðŸ“Œ **Important**: This file was generated by running **Step 2** of the [Seed Data Notebook](https://colab.research.google.com/drive/14tSNSP8Pe-mY4VwX9JhXgfyOvzmN3kC0?usp=sharing#scrollTo=OFKp4E49651Z)\n",
        "\n",
        "The file should now be downloaded and ready to upload to `/content/upload_results.csv`\n",
        "\n",
        "## Step 3: Upload `submit.zip`\n",
        "\n",
        "Upload the `submit.zip` file to the `/content/` directory.\n",
        "\n",
        "> ðŸ“Œ **Important**: This file was generated by running **Step 3** of the [County Data Notebook](https://colab.research.google.com/drive/1ZI_eScKFh2kDIZgwXljhOgBIgrenDhRi#scrollTo=HA0ppLFpUm1j)\n",
        "\n",
        "The file should now be downloaded and ready to upload to `/content/submit.zip`\n",
        "\n",
        "## Step 4: Verify Data Exists\n",
        "\n",
        "Once both files are uploaded to `/content/`, you can proceed with the main workflow that depends on these generated datasets.\n",
        "\n",
        "**Expected file locations:**\n",
        "- `/content/upload-results.csv`\n",
        "- `/content/submit.zip`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /content/upload-results.csv\n",
        "!ls -la /content/submit.zip"
      ],
      "metadata": {
        "id": "OC5QrF0XnIJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F000A7O3PtrJ"
      },
      "source": [
        "##Step 5: Install Package & Setup Folders (Total Runtime ~ 2 minutes)\n",
        "This step:\n",
        "\n",
        "Installs the photo-meta-data-ai package from GitHub\n",
        "Creates all necessary folders for the project\n",
        "Saves installation details to a log file for troubleshooting\n",
        "\n",
        "Takes 1-2 minutes to complete. Once finished, you'll have the AI package installed and folder structure ready for processing photos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiY6rgFYPvU6"
      },
      "outputs": [],
      "source": [
        "# 1. Install the package\n",
        "!pip install --force-reinstall --no-cache-dir git+https://github.com/elephant-xyz/photo-meta-data-ai.git > /content/install_log.txt 2>&1\n",
        "\n",
        "# 2. Set up folders\n",
        "!colab-folder-setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojt2s4z6NxC1"
      },
      "source": [
        "##Step 6: Upload Images to Property Subfolders\n",
        "Upload your property images into the pre-created subfolders:\n",
        "\n",
        "Each property already has a subfolder named with its Parcel ID under the images folder\n",
        "Simply drag and drop your images into the correct property subfolder\n",
        "All images for a specific property should go in that property's designated folder\n",
        "\n",
        "The AI will process each property's images and generate metadata organized by Parcel ID.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "y04HMnMuiAT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8 Uploading Photos"
      ],
      "metadata": {
        "id": "fX_uvmsi1wro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Elephant Fact Sheet Template Installer (Silent)\n",
        "set -e  # Exit on any error\n",
        "\n",
        "INSTALL_DIR=\"${HOME}/.elephant-fact-sheet\"\n",
        "BIN_DIR=\"${HOME}/.local/bin\"\n",
        "STATIC_TARGET_DIR=\"$BIN_DIR/templates/assets/static\"\n",
        "TEST=\"/content/templates/assets/static\"\n",
        "\n",
        "# Check Node.js version\n",
        "if ! command -v node &> /dev/null; then\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "NODE_VERSION=$(node -v | cut -d'v' -f2 | cut -d'.' -f1)\n",
        "if [ \"$NODE_VERSION\" -lt 18 ]; then\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "# Check npm\n",
        "if ! command -v npm &> /dev/null; then\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "# Clean up any existing installation\n",
        "rm -rf \"$INSTALL_DIR\"\n",
        "\n",
        "# Clone repo silently\n",
        "git clone --quiet https://github.com/elephant-xyz/fact-sheet-template.git \"$INSTALL_DIR\"\n",
        "\n",
        "cd \"$INSTALL_DIR\"\n",
        "\n",
        "# Silent npm install and build\n",
        "npm install --silent --no-audit --no-fund > /dev/null 2>&1\n",
        "npm run build --silent > /dev/null 2>&1\n",
        "\n",
        "# Setup directories and copy assets\n",
        "mkdir -p \"$BIN_DIR\" \"$STATIC_TARGET_DIR\" \"$TEST\"\n",
        "cp -r \"$INSTALL_DIR/templates/assets/static/\"* \"$STATIC_TARGET_DIR\"\n",
        "cp -r \"$INSTALL_DIR/templates/assets/static/\"* \"$TEST\"\n",
        "\n",
        "# Link and make executable\n",
        "ln -sf \"$INSTALL_DIR/bin/fact-sheet.js\" \"$BIN_DIR/fact-sheet\"\n",
        "chmod +x \"$INSTALL_DIR/bin/fact-sheet.js\""
      ],
      "metadata": {
        "id": "FYnk4e4uqyEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Step 1: Process photo data\n",
        "process-photo-data\n",
        "\n",
        "# Step 2: Unzip the submission archive\n",
        "unzip submit.zip >> logs/zip.log\n",
        "\n",
        "# Step 3: Copy all contents from submit/* to photo_data_group/*\n",
        "for dir in submit/*/; do\n",
        "  dir_name=$(basename \"$dir\")\n",
        "  mkdir -p \"photo_data_group/$dir_name\"\n",
        "  cp -r \"$dir\"* \"photo_data_group/$dir_name/\"\n",
        "done\n",
        "\n",
        "\n",
        "#Step 4: Validate and upload the data\n",
        "npx -y @elephant-xyz/cli@latest validate-and-upload photo_data_group --output-csv photos.csv\n",
        "\n"
      ],
      "metadata": {
        "id": "FL2oPh-S3eya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Submitting Your Data to the Blockchain\n",
        "\n",
        "### Submitting Your Data\n",
        "\n",
        "Once complete, your data is permanently recorded on the blockchain. You'll receive vMahout tokens as rewards after consensus is reached (when 3 different oracles submit matching data hashes)."
      ],
      "metadata": {
        "id": "cAxcVrYl7vA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npx -y @elephant-xyz/cli submit-to-contract photos.csv"
      ],
      "metadata": {
        "id": "AId1ovFzgVlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJo3i5enWo0J"
      },
      "source": [
        "## Step 10: Setup and Run AWS Rekognition (Total Runtime ~ 3 minutes)\n",
        "\n",
        "The system automatically sets up and runs Amazon Rekognition to analyze your property images:\n",
        "\n",
        "- Connects to AWS Rekognition service for AI-powered image analysis\n",
        "- Processes all images in your property folders automatically\n",
        "- Extracts detailed information like room types, architectural features, and property characteristics\n",
        "\n",
        "No action needed from you - the system handles everything automatically and will notify you when processing is complete.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2eZfzTpOGV0"
      },
      "outputs": [],
      "source": [
        "!bucket-manager\n",
        "!unzip-county-data\n",
        "!upload-to-s3\n",
        "!photo-categorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo7Jjafq6N1i"
      },
      "source": [
        "## Step 11: Running AI to Extract Data from Images (Total Runtime ~ 7 minutes)\n",
        "\n",
        "The AI system now analyzes your property images to extract valuable metadata:\n",
        "\n",
        "1. **Image Analysis**: AI examines each photo to identify rooms, features, and property details\n",
        "2. **Data Extraction**: System pulls out structured information like room types, square footage estimates, architectural elements, and condition assessments\n",
        "\n",
        "The process runs automatically across all your uploaded property images, generating comprehensive metadata reports for each parcel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67Sqqv2xcurU"
      },
      "outputs": [],
      "source": [
        "!pip install --force-reinstall --no-cache-dir git+https://github.com/elephant-xyz/photo-meta-data-ai.git > /content/install_log.txt 2>&1\n",
        "\n",
        "!ai-analyzer --local-folders --parallel-categories --all-properties\n",
        "!property-summarizer --all-properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WEPamAD7h4F"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKHWrLc47vUv"
      },
      "source": [
        "## Step 12: Data Validation and Submission\n",
        "\n",
        "The system validates extracted data and prepares it for final submission:\n",
        "\n",
        "1. **Data Validation**: Reviews and verifies all extracted metadata for accuracy\n",
        "2. **Submission Preparation**: Validated data is formatted and organized for CLI submission\n",
        "3. **CLI Submission**: System automatically submits the processed data through the command line interface\n",
        "4. **Fact Sheet Generation**: Creates comprehensive property fact sheets with all extracted information, images, and metadata\n",
        "\n",
        "Final deliverables include validated property reports and detailed fact sheets ready for use.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Elephant Fact Sheet Template Installer (Silent)\n",
        "set -e  # Exit on any error\n",
        "\n",
        "INSTALL_DIR=\"${HOME}/.elephant-fact-sheet\"\n",
        "BIN_DIR=\"${HOME}/.local/bin\"\n",
        "STATIC_TARGET_DIR=\"$BIN_DIR/templates/assets/static\"\n",
        "TEST=\"/content/templates/assets/static\"\n",
        "\n",
        "# Check Node.js version\n",
        "if ! command -v node &> /dev/null; then\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "NODE_VERSION=$(node -v | cut -d'v' -f2 | cut -d'.' -f1)\n",
        "if [ \"$NODE_VERSION\" -lt 18 ]; then\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "# Check npm\n",
        "if ! command -v npm &> /dev/null; then\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "# Clean up any existing installation\n",
        "rm -rf \"$INSTALL_DIR\"\n",
        "\n",
        "# Clone repo silently\n",
        "git clone --quiet https://github.com/elephant-xyz/fact-sheet-template.git \"$INSTALL_DIR\"\n",
        "\n",
        "cd \"$INSTALL_DIR\"\n",
        "\n",
        "# Silent npm install and build\n",
        "npm install --silent --no-audit --no-fund > /dev/null 2>&1\n",
        "npm run build --silent > /dev/null 2>&1\n",
        "\n",
        "# Setup directories and copy assets\n",
        "mkdir -p \"$BIN_DIR\" \"$STATIC_TARGET_DIR\" \"$TEST\"\n",
        "cp -r \"$INSTALL_DIR/templates/assets/static/\"* \"$STATIC_TARGET_DIR\"\n",
        "cp -r \"$INSTALL_DIR/templates/assets/static/\"* \"$TEST\"\n",
        "\n",
        "# Link and make executable\n",
        "ln -sf \"$INSTALL_DIR/bin/fact-sheet.js\" \"$BIN_DIR/fact-sheet\"\n",
        "chmod +x \"$INSTALL_DIR/bin/fact-sheet.js\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ws5HypL7uEsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z33zRmVR7zVn"
      },
      "outputs": [],
      "source": [
        "!fix-schema-validation\n",
        "!copy-all-data-for-submission\n",
        "!copy-all-files-from-zip\n",
        "!npx @elephant-xyz/cli@latest validate-and-upload submit-photo --output-csv submit-results.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 13: Submitting Your Data to the Blockchain\n",
        "\n",
        "### Submitting Your Data\n",
        "\n",
        "Once complete, your data is permanently recorded on the blockchain. You'll receive vMahout tokens as rewards after consensus is reached (when 3 different oracles submit matching data hashes)."
      ],
      "metadata": {
        "id": "-DsIg-MR3Rrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npx -y @elephant-xyz/cli submit-to-contract submit-results.csv"
      ],
      "metadata": {
        "id": "O4hTCp0Smrbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 14: Package and Download Results\n",
        "\n",
        "This step creates downloadable files with all your processed data. The system will:\n",
        "\n",
        "1. **Create Download Package**: Automatically zip the submit-photos folder containing all fact sheets and processed images\n",
        "\n",
        "2. **Download Results**: Two files will be made available for download\n",
        "\n",
        "**Files to Download:**\n",
        "- `submit-results.csv` - Structured data with all extracted property metadata\n",
        "- `submit-photo.zip` - Complete package containing fact sheets and processed images\n",
        "\n",
        "Your processed property data is now saved locally for use."
      ],
      "metadata": {
        "id": "KEeTcfuy5dEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r submit-photo.zip submit-photo/ > /dev/null 2>&1\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8Jw-Bxu6Oa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 15: Cleanup\n",
        "\n",
        "Final and optional step to save your results and clean up the workspace:\n",
        "\n",
        "3. **Cleanup Workspace**: After downloading, the system removes all temporary files and folders including:\n",
        "  - `images` folder (uploaded property photos)\n",
        "  - `output` folder (processing files)\n",
        "  - `county-data` folder (temporary data)\n",
        "  - `submit-photos` folder (final results)\n",
        "  - `logs` folder (processing logs)\n",
        "\n",
        "**Important**: Make sure to download your results before the cleanup step, as all files will be permanently deleted from the workspace."
      ],
      "metadata": {
        "id": "t4sJUpBJ8uru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf images/ output/ county-data/ submit/ submit-photo/ logs/ photo_data_group/ > /dev/null 2>&1\n",
        "!find . -maxdepth 1 -type f \\( -name \"*.csv\" -o -name \"*.zip\" -o -name \"*.jpg\" -o -name \"*.txt\" -o -name \"*.log\" -o -name \".env\" \\) -exec rm -f {} \\;\n",
        "\n",
        "!rm -rf /root/.local/bin/fact-sheet\n",
        "!rm -rf fact-sheet-template/\n",
        "!rm -rf /root/.elephant-fact-sheet"
      ],
      "metadata": {
        "id": "HTwgC_Wd8_pA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}